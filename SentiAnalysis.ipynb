{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis (Movie Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with the project: step one would be downloading the data and playing with it. Use pandas to load the data, actual data is in *.tsv format. One can load that or I converted it in csv format and used it (4-5 lines had some special characters which caused problem in loading the dataset, but after removing those special characters, dataset can be loaded normaly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('./train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use: dataset.info() to get the summary of different columns, if any column contains any row (if yes, then how many?) with Na values. Use datase.head(), dataset.tail(), dataset.describe(), dataset['$ColumnName'] e.t.c to gain more insight into the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use: dataset.$ColumnName.value_count() to get the information about any particular column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proceed further with the sentiment analysis we need to do text classification. We can use 'bag of words (BOW)' model for the analysis. In laymen terms BOW model converts text in the form of numbers which can then be used in an algorithm for analysis.\n",
    "\n",
    "Specifically BOW model is used for feature extraction in text data. It returns a vector with all the words and number of times each word is repeated. It is known as BOW because it is only concerned with the number of times a word is repeated rather than order of words. Let's take an example to understand it better (assume each document contains a sentence only):\n",
    "\n",
    "    Doc1: Switzerland is a beautiful country. \n",
    "    Doc2: India is a country of smart IT professionals. \n",
    "    Doc3: USA is a country of opportunities. \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Table below is known as document term matrix (DTM). \n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "| Unique Words -> Switzwerland  is  a beautiful country India of smart IT professionals USA opportunities \n",
    "| Doc 1 Vector ->       1       1   1     1         1     0    0   0    0      0         0       0     \n",
    "| Doc 2 Vector ->       0       1   1     0         1     1    1   1    1      1         0       0 \n",
    "| Doc 3 Vector ->       0       1   1     0         1     0    1   0    0      0         1       1 \n",
    "| Cumulative   ->       1       3   3     1         3     1    2   1    1      1         1       1 \n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "The model shown above is a monogram model. If two words are taken at a time (for ex: Switzerland is, is a, a beautiful, beautiful country, ... then it is known as bi-gram model similarly for N words at a time it will be N-gram model. A higher gram model tends to work better than monogram model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More the content in each document lengthier would be the length of each vector (will contain lot of zeros). Basically doc vectors would be a sparse vectors if documents are too large. Sparse vectors need lot of memory for storage and due to length even computation becomes slow. In order to reduce the length of the sparse vectors one may use the technique like stemming, lematization, converting to lower case or ignoring stop-words e.t.c. \n",
    "\n",
    "Now, we will generate DTM using CountVectorizer module of scikit-learn. To read more about the arguments of CountVectorizer you may visit __[here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)__. As discussed above we will use:<br>\n",
    "<ul>\n",
    "<li>tokenizer = Overrides the string tokenization step, we generatre tokenizer from NLTK's Regex tokenizer (by default: None)</li>\n",
    "<li>lowercase = True (no need to use, as it is set True by default)</li>\n",
    "<li>stop_words = 'english' (by default None is used, to improve the result we can provide custom made list of stop words)</li>\n",
    "<li>ngram_range = (1,1) (by defualt its (1,1) i.e strictly monograms will be used, (2,2) only bigrams while (1,2) uses both)</li>\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['Phrase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data for training and testing to check how well our model has performed. Also we will randomize the data in case our data includes all positive first and then all negative or some other kind of bias. We will use: scikit_learn's __[train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)__ for splitting the text_count (which contains our X) and dataset['Sentiment'] (this contains Y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the training and testing data. We should start the analysis. Our analysis (as most of ML analysis) will be in 5 steps(a mneumonic to remember them is <b>DC-FEM</b> remember as DC Female or District of Columbia Fire and Emergency Medical service): \n",
    "<ol>\n",
    "    <li>Defining the model</li>\n",
    "    <li>Compiling the model</li>\n",
    "    <li>Fitting the model</li>\n",
    "    <li>Evaluating the model</li>\n",
    "    <li>Making predictions with the model</li>\n",
    "</ol>\n",
    " \n",
    "### 1. Defining the model\n",
    "We will use one of the __[Naive Bayes (NB)](https://scikit-learn.org/stable/modules/naive_bayes.html)__ classifier for defining the model. Specifically we will use __[MultinomialNB classifier](https://scikit-learn.org/stable/modules/naive_bayes.html)__. As a fresher to ML one can use cheat sheet given by sklearn __[here](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)__ to determine the best model to use for a particular problem. It tell us to use NB classifier. Let us take a detour to learn more about NB model. \n",
    "####  Naive Bayes Model\n",
    "This model applies Bayes theorem with a Naive assumption of no relation between different features. According to Bayes theorem:<br>\n",
    "\n",
    "Posterior = likelihood * proposition/evidedence or  P(A|B) = P(B|A) * P(A)/P(B)<br>\n",
    "<b>For ex: In a deck of playing cards, a card is chosen. What is the probability of a card being queen given the card is a face card?</b><br>\n",
    "This can be solved using Bayes theorem.<br>\n",
    "P(Queen given Face card) = P(Queen|Face)<br> \n",
    "P(Face given Queen) = P(Face|Queen) = 1<br>\n",
    "P(Queen) = 4/52 = 1/13\n",
    "P(Face) = 3/13\n",
    "From Bayes theore:<br>\n",
    "P(Queen|Face) = P(Face|Queen) P(Queen)/P(Face) = 1/3<br>\n",
    "\n",
    "\n",
    "\n",
    "For an input with several variables:<br>\n",
    "P(y|x1, x2, ... xn) = P(x1, x2, ... xn|y)* P(y)/P(x1,x2, ...xn)<br>\n",
    "with Naive Bayes we assume x1, x2 ... xn are independent of each other, i.e:<br>\n",
    "P(x1, x2, ... xn|y) = P(x1|y) * P(x2|y) ... * P(xn|y)<br> \n",
    "The assumption in distribution of P(xi|y) give rise to different NBM. For example assuming Gaussian distribution will give rise to Gaussian Naive Bayes (GNB) or multinomial distribusion will give Multinomial Naive Bayes (MNB). \n",
    "\n",
    "Naive Bayes Model works particularly well with text classification and spam filtering. <b>Advantages</b> of working with NB algorithm are:\n",
    "<ul>\n",
    "    <li>Requires small amount of training data to learn the parameters</li>\n",
    "    <li>Can be trained relatively fast compared to sophisticated models</li>\n",
    "</ul>\n",
    "Main <b>disadvantage</b> of NB Algorithm is:\n",
    "<ul>\n",
    "    <li>It's a decent classifier but a bad estimator</li>\n",
    "    <li>It works well with discrete values but won't work with continuous values (can't be used in regression)</li>\n",
    "</ul>\n",
    "\n",
    "#### Dilemma of NB Algorithm\n",
    "A challenging question which can be asked regarding NB algorithm is: although the condinal independence assumed in NB algorithm is hardly true in real life then howcome NB Algorithm work so well as classifier? \n",
    "I won't discuss the solution here, rather will direct you towards the resource which contains the solution (__[here](https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf)__). In short the answer lies in distribution of dependencies rather than dependency, somehow due to distribution the effect of dependencies cancels out. \n",
    "\n",
    "#### Loss function for NB classification\n",
    "NB classification uses a zero-one loss function. In this function error = number of incorrect classifications. Here accuracy of probability estimation is not taken into account by error function given that class with highest probability is predicted right. For example let's say there are two classes A and B, and different attributes (x1, x2, ... xn) are given. P(A|all atributes) = 0.95 and P(B|all atributes)=0.05 but NB might estimates P(A|all atributes) = 0.7 and P(B|all atributes) = 0.3. Here althogh estimates are far from accurate but classifiction is correct.\n",
    "\n",
    "Let's move back to our analysis. The first two steps of defining and compiling the model are reduced to identifying and importing the model from sklearn (as sklearn gives as precompiled models).\n",
    "\n",
    "### 2. Compiling the model\n",
    "Since we are using sklearn's modules and classes we just need to import the precompiled classes. Sklearn gives the information of all the classes __[here](https://scikit-learn.org/stable/modules/classes.html)__.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fitting the model\n",
    "In this step we generate our model fitting our dataset in the MultinomialNB. Inorder to look for the arguments which can be passed while fitting the model its advised to check the sklearn webpage of the module under use. For MNB it can be checked __[here](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluating the model\n",
    "Here we quantify the quality of our model. We use __[metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation)__ module from sklearn library to evaluate the predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.25%\n"
     ]
    }
   ],
   "source": [
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking the model\n",
    "We have observed the accuracy of our model is over 60%. We can now play with our model to increase its' accuracy.\n",
    "\n",
    "#### Trying different n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.37%\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction import CountVectorizer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#token = RegexpTokenizer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['Phrase'])\n",
    "\n",
    "#from sklearn.model_selection import train_test_split()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.25, random_state=5)\n",
    "\n",
    "#Defining the model-> we will use MultinomialNB\n",
    "\n",
    "#Compiling the model -> We will import precompiled MNB from sklearn library\n",
    "#from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "#Fitting the model\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "#Evaulating the model\n",
    "#form sklearn import metrics\n",
    "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.86%\n"
     ]
    }
   ],
   "source": [
    "#It shows only a marginal imporvement, let us try with trigram tokenization now:\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (3,3), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['Phrase'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['Sentiment'],test_size=0.25, random_state=5)\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different Naive Bayes Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.53%\n"
     ]
    }
   ],
   "source": [
    "#With this particular MNB model we are gaining success which is close to 60%, nomatter what n-gram vectorization we opt for.\n",
    "#Let's try to change the model to ComplementNB. \n",
    "\n",
    "#let's write the complete code assuming we have our data imported to dataset.\n",
    "\n",
    "#from sklearn.feature_extraction import CountVectorizer\n",
    "#from nlkt.tokenize import RegexpTokenizer\n",
    "#token = RegexpTokenixer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,1), tokenizer=token.tokenize)\n",
    "text_count = cv.fit_transform(dataset['Phrase'])\n",
    "\n",
    "#split the dataset in train test \n",
    "#form sklearn.model_selection() import train_test_split()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_count, dataset['Sentiment'], test_size=0.25, random_state=2)\n",
    "\n",
    "#Defining and compiling the model -> we will use ComplementNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "#Fitting the model\n",
    "CNB = ComplementNB()\n",
    "CNB.fit(X_train, Y_train)\n",
    "\n",
    "#evaluating the model\n",
    "#from sklearn import metrics\n",
    "accuracy_score = metrics.accuracy_score(CNB.predict(X_test),Y_test)\n",
    "\n",
    "print(str('{:4.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about using several different algorithms all at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB accuracy = 47.53%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train.todense(), Y_train)\n",
    "accuracy_score = metrics.accuracy_score(CNB.predict(X_test),Y_test)\n",
    "\n",
    "print('GNB accuracy = ' + str('{:4.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB accuracy = 60.61%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "BNB = BernoulliNB()\n",
    "BNB.fit(X_train, Y_train)\n",
    "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(X_test),Y_test)\n",
    "print('BNB accuracy = ' + str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the accuracy\n",
    "We have tried using different n-grams and different Naive Bayes models but maximum accuracy lingers arround 60%. In order to improve our model let's try to change the way the BOW is created. Currently we created BOW with CountVectorizer which counts the occurance of the word in the text. More number of time a word occurs it becomes more important for classification. \n",
    "\n",
    "\n",
    "### TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "Let's use TF-IDF here product of term frequency and inverse document frequency is used. Term frequency is how frequently a terms has appeared in a document. Let's say a term appears f times in a document with d words. <br>\n",
    "Term Frequency = f/d <br>\n",
    "IDF is inverse document frequency. If a corpus contains N documents and the term of our interest appears only in D documents then IDF is:<br>\n",
    "IDF = log(N/D)\n",
    "TF-IDF is product of Term Frequncy and Inverse Document Frequency. <b>TF-IDF shows the rarity of a word in the corpus.</b> If a word is rare then probably its a signature word for a particular sentiment/information.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_mnb = 58.50%\n",
      "accuracy_score_bnb = 59.33%\n",
      "accuracy_score_cnb = 51.42%\n",
      "accuracy_score_gnb = 19.97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(dataset['Phrase'])\n",
    "\n",
    "#splitting the data in test and training\n",
    "#from sklearn.model_selection() import train_test_split()\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, dataset['Sentiment'],test_size=0.25,random_state=5)\n",
    "\n",
    "#defining the model\n",
    "#compilimg the model -> we are going to use already used models GNB, MNB, CNB, BNB\n",
    "#fitting the model\n",
    "MNB.fit(x_train, y_train)\n",
    "accuracy_score_mnb = metrics.accuracy_score(MNB.predict(x_test), y_test)\n",
    "print('accuracy_score_mnb = '+str('{:4.2f}'.format(accuracy_score_mnb*100))+'%')\n",
    "\n",
    "BNB.fit(x_train, y_train)\n",
    "accuracy_score_bnb = metrics.accuracy_score(BNB.predict(x_test), y_test)\n",
    "print('accuracy_score_bnb = '+str('{:4.2f}'.format(accuracy_score_bnb*100))+'%')\n",
    "\n",
    "CNB.fit(x_train, y_train)\n",
    "accuracy_score_cnb = metrics.accuracy_score(CNB.predict(x_test), y_test)\n",
    "print('accuracy_score_cnb = '+str('{:4.2f}'.format(accuracy_score_cnb*100))+'%')\n",
    "\n",
    "GNB.fit(x_train.todense(), y_train)\n",
    "accuracy_score_gnb = metrics.accuracy_score(GNB.predict(x_test.todense()), y_test)\n",
    "print('accuracy_score_gnb = '+str('{:4.2f}'.format(accuracy_score_gnb*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying non Bayesian algorithms\n",
    "Even the Tfidf vectorizer i.e creating a different BOW didn't help in imporving the accuracy of the model. Rather than naive bayes algorithm we can also opt for stochastic gradient descent classifier or linear support vector classifier. Both of these are known to work well with the text data classification. Let's try to use these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_lsvc = 63.88%\n",
      "accuracy_score_sgdc = 56.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnshs\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_lsvc_cv = 63.05%\n",
      "accuracy_score_sgdc_cv = 60.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "SGDC = SGDClassifier()\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "#on TF-IDF data\n",
    "LSVC.fit(x_train, y_train)\n",
    "accuracy_score_lsvc = metrics.accuracy_score(LSVC.predict(x_test), y_test)\n",
    "print('accuracy_score_lsvc = '+str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')\n",
    "\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "\n",
    "#on CountVectorize data\n",
    "LSVC.fit(X_train, Y_train)\n",
    "accuracy_score_lsvc_CV = metrics.accuracy_score(LSVC.predict(X_test), Y_test)\n",
    "print('accuracy_score_lsvc_cv = '+str('{:4.2f}'.format(accuracy_score_lsvc_CV*100))+'%')\n",
    "\n",
    "SGDC.fit(X_train, Y_train)\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(X_test), Y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
